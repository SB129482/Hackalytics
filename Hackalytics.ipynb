{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWc0_B01457Q"
      },
      "source": [
        "# Download Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVcYBJcx45nh",
        "outputId": "047e6aa7-ef8d-4122-fb95-85896a8915e5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing HeStutters 0\n",
            "Processing HeStutters 1\n",
            "Processing HeStutters 2\n",
            "Processing HeStutters 3\n",
            "Processing HeStutters 4\n",
            "Processing HeStutters 5\n",
            "Processing HeStutters 6\n",
            "Processing HeStutters 7\n",
            "Processing HeStutters 8\n",
            "Processing HeStutters 9\n",
            "Processing HeStutters 10\n",
            "Processing HeStutters 11\n",
            "Processing HeStutters 12\n",
            "Processing HeStutters 13\n",
            "Processing HeStutters 14\n",
            "Processing HeStutters 15\n",
            "Processing HeStutters 16\n",
            "Processing HeStutters 17\n",
            "Processing HeStutters 18\n",
            "Processing HeStutters 19\n",
            "Processing HeStutters 20\n",
            "Processing HeStutters 21\n",
            "Processing HeStutters 22\n",
            "Processing HeStutters 23\n",
            "Processing HVSA 0\n",
            "Processing HVSA 1\n",
            "Processing HVSA 2\n",
            "Processing HVSA 3\n",
            "Processing IStutterSoWhat 0\n",
            "Processing IStutterSoWhat 1\n",
            "Processing IStutterSoWhat 2\n",
            "Processing IStutterSoWhat 3\n",
            "Processing IStutterSoWhat 4\n",
            "Processing MyStutteringLife 0\n",
            "Processing MyStutteringLife 1\n",
            "Processing MyStutteringLife 2\n",
            "Processing MyStutteringLife 3\n",
            "Processing MyStutteringLife 4\n",
            "Processing MyStutteringLife 5\n",
            "Processing MyStutteringLife 6\n",
            "Processing MyStutteringLife 7\n",
            "Processing MyStutteringLife 8\n",
            "Processing MyStutteringLife 9\n",
            "Processing MyStutteringLife 10\n",
            "Processing MyStutteringLife 11\n",
            "Processing MyStutteringLife 12\n",
            "Processing MyStutteringLife 13\n",
            "Processing MyStutteringLife 14\n",
            "Processing MyStutteringLife 15\n",
            "Processing MyStutteringLife 16\n",
            "Processing MyStutteringLife 17\n",
            "Processing MyStutteringLife 18\n",
            "Processing MyStutteringLife 19\n",
            "Processing MyStutteringLife 20\n",
            "Processing MyStutteringLife 21\n",
            "Processing MyStutteringLife 22\n",
            "Processing MyStutteringLife 23\n",
            "Processing MyStutteringLife 24\n",
            "Processing MyStutteringLife 25\n",
            "Processing MyStutteringLife 26\n",
            "Processing MyStutteringLife 27\n",
            "Processing MyStutteringLife 28\n",
            "Processing MyStutteringLife 29\n",
            "Processing MyStutteringLife 30\n",
            "Processing MyStutteringLife 31\n",
            "Processing MyStutteringLife 32\n",
            "Processing MyStutteringLife 33\n",
            "Processing MyStutteringLife 34\n",
            "Processing MyStutteringLife 35\n",
            "Processing MyStutteringLife 36\n",
            "Processing MyStutteringLife 37\n",
            "Processing MyStutteringLife 38\n",
            "Processing MyStutteringLife 39\n",
            "Processing StrongVoices 0\n",
            "Processing StrongVoices 1\n",
            "Processing StrongVoices 2\n",
            "Processing StrongVoices 3\n",
            "Processing StrongVoices 4\n",
            "Processing StrongVoices 5\n",
            "Processing StrongVoices 6\n",
            "Processing StrongVoices 7\n",
            "Processing StrongVoices 8\n",
            "Processing StrongVoices 9\n",
            "Processing StrongVoices 10\n",
            "Processing StrongVoices 11\n",
            "Processing StrongVoices 12\n",
            "Processing StrongVoices 13\n",
            "Processing StrongVoices 14\n",
            "Processing StrongVoices 15\n",
            "Processing StrongVoices 16\n",
            "Processing StrongVoices 17\n",
            "Processing StrongVoices 18\n",
            "Processing StrongVoices 19\n",
            "Processing StrongVoices 20\n",
            "Processing StrongVoices 21\n",
            "Processing StrongVoices 22\n",
            "Processing StrongVoices 23\n",
            "Processing StrongVoices 24\n",
            "Processing StrongVoices 25\n",
            "Processing StrongVoices 26\n",
            "Processing StrongVoices 27\n",
            "Processing StrongVoices 28\n",
            "Processing StrongVoices 29\n",
            "Processing StrongVoices 30\n",
            "Processing StrongVoices 31\n",
            "Processing StrongVoices 32\n",
            "Processing StrongVoices 33\n",
            "Processing StrongVoices 34\n",
            "Processing StutterTalk 0\n",
            "Processing StutterTalk 1\n",
            "Processing StutterTalk 2\n",
            "Processing StutterTalk 3\n",
            "Processing StutterTalk 4\n",
            "Processing StutterTalk 5\n",
            "Processing StutterTalk 6\n",
            "Processing StutterTalk 7\n",
            "Processing StutterTalk 8\n",
            "Processing StutterTalk 9\n",
            "Processing StutterTalk 10\n",
            "Processing StutterTalk 11\n",
            "Processing StutterTalk 12\n",
            "Processing StutterTalk 13\n",
            "Processing StutterTalk 14\n",
            "Processing StutterTalk 15\n",
            "Processing StutterTalk 16\n",
            "Processing StutterTalk 17\n",
            "Processing StutterTalk 18\n",
            "Processing StutterTalk 19\n",
            "Processing StutterTalk 20\n",
            "Processing StutterTalk 21\n",
            "Processing StutterTalk 22\n",
            "Processing StutterTalk 23\n",
            "Processing StutterTalk 24\n",
            "Processing StutterTalk 25\n",
            "Processing StutterTalk 26\n",
            "Processing StutterTalk 27\n",
            "Processing StutterTalk 28\n",
            "Processing StutterTalk 29\n",
            "Processing StutterTalk 30\n",
            "Processing StutterTalk 31\n",
            "Processing StutterTalk 32\n",
            "Processing StutterTalk 33\n",
            "Processing StutterTalk 34\n",
            "Processing StutterTalk 35\n",
            "Processing StutterTalk 36\n",
            "Processing StutterTalk 37\n",
            "Processing StutterTalk 38\n",
            "Processing StutterTalk 39\n",
            "Processing StutterTalk 40\n",
            "Processing StutterTalk 41\n",
            "Processing StutterTalk 42\n",
            "Processing StutterTalk 43\n",
            "Processing StutterTalk 44\n",
            "Processing StutterTalk 45\n",
            "Processing StutterTalk 46\n",
            "Processing StutterTalk 47\n",
            "Processing StutterTalk 48\n",
            "Processing StutterTalk 49\n",
            "Processing StutterTalk 50\n",
            "Processing StutterTalk 51\n",
            "Processing StutterTalk 52\n",
            "Processing StutterTalk 53\n",
            "Processing StutterTalk 54\n",
            "Processing StutterTalk 55\n",
            "Processing StutterTalk 56\n",
            "Processing StutterTalk 57\n",
            "Processing StutterTalk 58\n",
            "Processing StutterTalk 59\n",
            "Processing StutterTalk 60\n",
            "Processing StutterTalk 61\n",
            "Processing StutterTalk 62\n",
            "Processing StutterTalk 63\n",
            "Processing StutterTalk 64\n",
            "Processing StutterTalk 65\n",
            "Processing StutterTalk 66\n",
            "Processing StutterTalk 67\n",
            "Processing StutterTalk 68\n",
            "Processing StutterTalk 69\n",
            "Processing StutterTalk 70\n",
            "Processing StutterTalk 71\n",
            "Processing StutterTalk 72\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# For licensing see accompanying LICENSE file.\n",
        "# Copyright (C) 2021 Apple Inc. All Rights Reserved.\n",
        "#\n",
        "\n",
        "\"\"\"\n",
        "For each podcast episode:\n",
        "* Download the raw mp3/m4a file\n",
        "* Convert it to a 16k mono wav file\n",
        "# Remove the original file\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import subprocess\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# import argparse\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='Download raw audio files for SEP-28k or FluencyBank and convert to 16k hz mono wavs.')\n",
        "# parser.add_argument('--episodes', type=str, required=True,\n",
        "#                    help='Path to the labels csv files (e.g., SEP-28k_episodes.csv)')\n",
        "# parser.add_argument('--wavs', type=str, default=\"wavs\",\n",
        "#                    help='Path where audio files from download_audio.py are saved')\n",
        "\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# episode_uri = args.episodes\n",
        "# wav_dir = args.wavs\n",
        "\n",
        "episode_uri = '../input/fluencybank_episodes.csv'\n",
        "wav_dir = '../input/fluencybank_rawWAVs'\n",
        "\n",
        "# Load episode data\n",
        "table = np.genfromtxt(episode_uri, dtype=str, delimiter=\", \")\n",
        "urls = table[:,2]\n",
        "n_items = len(urls)\n",
        "\n",
        "audio_types = [\".mp3\", \".m4a\", \".mp4\"]\n",
        "\n",
        "\n",
        "for i in range(n_items):\n",
        "\t# Get show/episode IDs\n",
        "\tshow_abrev = table[i,-2]\n",
        "\tep_idx = table[i,-1]\n",
        "\tepisode_url = table[i,2]\n",
        "\n",
        "\t# Check file extension\n",
        "\text = ''\n",
        "\tfor ext in audio_types:\n",
        "\t\tif ext in episode_url:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t# Ensure the base folder exists for this episode\n",
        "\tepisode_dir = pathlib.Path(f\"{wav_dir}/{show_abrev}/\")\n",
        "\tos.makedirs(episode_dir, exist_ok=True)\n",
        "\n",
        "\t# Get file paths\n",
        "\taudio_path_orig = pathlib.Path(f\"{episode_dir}/{ep_idx}{ext}\")\n",
        "\twav_path = pathlib.Path(f\"{episode_dir}/{ep_idx}.wav\")\n",
        "\n",
        "\t# Check if this file has already been downloaded\n",
        "\tif os.path.exists(wav_path):\n",
        "\t\tcontinue\n",
        "\n",
        "\tprint(\"Processing\", show_abrev, ep_idx)\n",
        "\t# Download raw audio file. This could be parallelized.\n",
        "\tif not os.path.exists(audio_path_orig):\n",
        "\t\tline = f\"wget -O {audio_path_orig} {episode_url}\"\n",
        "\t\tprocess = subprocess.Popen([(line)],shell=True)\n",
        "\t\tprocess.wait()\n",
        "\n",
        "\t# Convert to 16khz mono wav file\n",
        "\tline = f\"ffmpeg -i {audio_path_orig} -ac 1 -ar 16000 {wav_path}\"\n",
        "\tprocess = subprocess.Popen([(line)],shell=True)\n",
        "\tprocess.wait()\n",
        "\n",
        "\t# Remove the original mp3/m4a file\n",
        "\tos.remove(audio_path_orig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iQxACAn5ZcH"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# For licensing see accompanying LICENSE file.\n",
        "# Copyright (C) 2021 Apple Inc. All Rights Reserved.\n",
        "#\n",
        "\n",
        "\"\"\"\n",
        "For each podcast episode:\n",
        "* Get all clip information for that episode\n",
        "* Save each clip as a new wav file.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import subprocess\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# import argparse\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='Extract clips from SEP-28k or FluencyBank.')\n",
        "# parser.add_argument('--labels', type=str, required=True,\n",
        "#                    help='Path to the labels csv files (e.g., SEP-28k_labels.csv)')\n",
        "# parser.add_argument('--wavs', type=str, default=\"wavs\",\n",
        "#                    help='Path where audio files from download_audio.py are saved')\n",
        "# parser.add_argument('--clips', type=str, default=\"clips\",\n",
        "#                    help='Path where clips should be extracted')\n",
        "# parser.add_argument(\"--progress\", action=\"store_true\",\n",
        "#                     help=\"Show progress\")\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# label_file = args.labels\n",
        "# data_dir = args.wavs\n",
        "# output_dir = args.clips\n",
        "\n",
        "# label_file = '../input/fluencybank_labels.csv'\n",
        "# data_dir = '../input/fluencybank_rawWAVs'\n",
        "# output_dir = '../input/fluencybank_clippedWAVs'\n",
        "\n",
        "label_file = '../input/SEP-28k_labels.csv'\n",
        "data_dir = '../input/SEP-28k_rawWAVs'\n",
        "output_dir = '../input/SEP-28k_clippedWAVs'\n",
        "\n",
        "# Load label/clip file\n",
        "data = pd.read_csv(label_file, dtype={\"EpId\":str})\n",
        "\n",
        "# Get label columns from data file\n",
        "shows = data.Show\n",
        "episodes = data.EpId\n",
        "clip_idxs = data.ClipId\n",
        "starts = data.Start\n",
        "stops = data.Stop\n",
        "labels = data.iloc[:,5:].values\n",
        "\n",
        "n_items = len(shows)\n",
        "\n",
        "loaded_wav = \"\"\n",
        "cur_iter = range(n_items)\n",
        "# if args.progress:\n",
        "#         from tqdm import tqdm\n",
        "#         cur_iter = tqdm(cur_iter)\n",
        "\n",
        "for i in cur_iter:\n",
        "\tclip_idx = clip_idxs[i]\n",
        "\tshow_abrev = shows[i]\n",
        "\tepisode = episodes[i].strip()\n",
        "\n",
        "\t# Setup paths\n",
        "\twav_path = f\"{data_dir}/{shows[i]}/{episode}.wav\"\n",
        "\tclip_dir = pathlib.Path(f\"{output_dir}/{show_abrev}/{episode}/\")\n",
        "\tclip_path = f\"{clip_dir}/{shows[i]}_{episode}_{clip_idx}.wav\"\n",
        "\n",
        "\tif not os.path.exists(wav_path):\n",
        "\t\tprint(\"Missing\", wav_path)\n",
        "\t\tcontinue\n",
        "\n",
        "\t# Verify clip directory exists\n",
        "\tos.makedirs(clip_dir, exist_ok=True)\n",
        "\n",
        "\t# Load audio. For efficiency reasons don't reload if we've already open the file.\n",
        "\tif wav_path != loaded_wav:\n",
        "\t\tsample_rate, audio = wavfile.read(wav_path)\n",
        "\t\tassert sample_rate == 16000, \"Sample rate must be 16 khz\"\n",
        "\n",
        "\t\t# Keep track of the open file\n",
        "\t\tloaded_wav = wav_path\n",
        "\n",
        "\t# Save clip to file\n",
        "\tclip = audio[starts[i]:stops[i]]\n",
        "\twavfile.write(clip_path, sample_rate, clip)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juYE3dYG25Qd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d00S74OX25Qd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "sns.set_theme(style=\"white\", palette=None)\n",
        "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
        "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu9QYOBj25Qe"
      },
      "source": [
        "# Spectogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8WSylAfKwce"
      },
      "outputs": [],
      "source": [
        "# List all files in the directory\n",
        "# source_directory = '../input/fluencybank_clippedWAVs/FluencyBank/'\n",
        "# destination_directory = '../output/fluencybank_spectograms'\n",
        "\n",
        "source_directory = '../input/SEP-28k_clippedWAVs/FluencyBank/'\n",
        "destination_directory = '../output/SEP-28k_spectograms'\n",
        "\n",
        "folders = os.listdir(source_directory)\n",
        "# Process each file\n",
        "for folder in folders:\n",
        "  folder_path = os.path.join(source_directory, folder)\n",
        "  # Check if the item in the directory is indeed a folder\n",
        "  if os.path.isdir(folder_path):\n",
        "    files = os.listdir(folder_path)\n",
        "    # Iterate over files in the current folder\n",
        "    for file in files:\n",
        "      if file.endswith('.wav'):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        # Process the data\n",
        "        y, sr = librosa.load(file_path)\n",
        "        D = librosa.stft(y)\n",
        "        S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "        flatten_S_db = S_db.flatten()\n",
        "\n",
        "        # Save the processed data with a new file extension\n",
        "        # Construct the new file path in the destination directory\n",
        "        new_file_path = os.path.join(destination_directory, f'{file[:-4]}.npy')\n",
        "\n",
        "        # Save the processed data\n",
        "        np.save(new_file_path, flatten_S_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsF-6VCZZHmg"
      },
      "source": [
        "# Create dataframe with label.csv and all the npy files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP2UbiibZGdC"
      },
      "outputs": [],
      "source": [
        "# Step 1: Read CSV files into DataFrames\n",
        "\n",
        "csv_file_path = '../input/SEP_28k_labels.csv'\n",
        "df = pd.read_csv(csv_file_path, delimiter=',', dtype={'ClipId': str})\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  # Extract EpId from the current row\n",
        "  ep_id = row['EpId']\n",
        "  # Pad EpId with leading zeros to ensure three digits\n",
        "  ep_id_padded = str(ep_id).zfill(3)\n",
        "  # Update the 'EpId' column in the DataFrame with the padded value\n",
        "  df.at[index, 'EpId'] = ep_id_padded\n",
        "  # Extract 'ClipId' from the current row and strip extra spaces\n",
        "  clip_id_stripped = row['ClipId'].strip()\n",
        "  # Update the 'ClipId' column in the DataFrame with the stripped value\n",
        "  df.at[index, 'ClipId'] = clip_id_stripped\n",
        "\n",
        "# Function to load the numpy array from .npy file\n",
        "def load_npy(file_path):\n",
        "  return np.load(file_path)\n",
        "\n",
        "# Folder containing the .npy files\n",
        "npy_folder = '../output/fluencybank_spectograms'\n",
        "\n",
        "# Iterate through the DataFrame and add a new column with the loaded numpy array\n",
        "for index, row in df.iterrows():\n",
        "  show, ep_id, clip_id = row['Show'], row['EpId'], row['ClipId']\n",
        "  npy_file_path = os.path.join(npy_folder, f'{show}_{ep_id}_{clip_id}.npy')\n",
        "\n",
        "  # Load the numpy array from the .npy file\n",
        "  numpy_array = load_npy(npy_file_path)\n",
        "\n",
        "  numpy_series = pd.Series(numpy_array)\n",
        "  # Add the Pandas Series as a new column to the DataFrame\n",
        "  df['NumpyData'] = numpy_series\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmOf0m77e6e_"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Show', 'EpId', 'ClipId', 'Start', 'Stop']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0HRt4VslEds"
      },
      "source": [
        "# Train from dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwt3m8LjlH00"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Split the DataFrame into X (input features) and y (output labels)\n",
        "X = df['NumpyData'].values.reshape(-1, 1)  # Reshape to ensure X is a 2D array\n",
        "y = df[['Unsure', 'PoorAudioQuality', 'Prolongation', 'Block', 'SoundRep', 'WordRep',\n",
        "        'DifficultToUnderstand', 'Interjection', 'NoStutteredWords', 'NaturalPause',\n",
        "        'Music', 'NoSpeech']].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(1,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(12, activation='sigmoid'))  # Output layer with 12 neurons for 12 output classes (your output labels)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n",
        "# Save the model\n",
        "model.save('../output/model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDxyOyF8_2yb"
      },
      "outputs": [],
      "source": [
        "!pip3 install tensorflowjs\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model, '../output/tensorflowjs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xF5N5wmrQBo"
      },
      "source": [
        "# Predict from model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltpOb1wMrSy2"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('../output/model.h5')\n",
        "\n",
        "# Process the data\n",
        "y, sr = librosa.load('../input/test4.mp3')\n",
        "D = librosa.stft(y)\n",
        "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "print(type(S_db))\n",
        "flatten_S_db = S_db.flatten()\n",
        "print(type(flatten_S_db))\n",
        "\n",
        "predictions = loaded_model.predict(X_new)\n",
        "print(type(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogTUTiyRws0D"
      },
      "outputs": [],
      "source": [
        "# Set a threshold (you can experiment with different values)\n",
        "threshold = 0.0001\n",
        "\n",
        "# Convert probabilities to binary values based on the threshold\n",
        "binary_predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "# Interpret the results\n",
        "categories = ['Unsure', 'PoorAudioQuality', 'Prolongation', 'Block', 'SoundRep', 'WordRep',\n",
        "              'DifficultToUnderstand', 'Interjection', 'NoStutteredWords', 'NaturalPause',\n",
        "              'Music', 'NoSpeech']\n",
        "\n",
        "result_dict = dict(zip(categories, binary_predictions.flatten()))\n",
        "\n",
        "# Display the results\n",
        "for category, prediction in result_dict.items():\n",
        "    print(f'{category}: {prediction}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zMyf1Yo6XVV"
      },
      "outputs": [],
      "source": [
        "average_prediction = np.mean(predictions, axis=0)\n",
        "\n",
        "print(average_prediction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 107620,
          "sourceId": 256618,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30162,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}